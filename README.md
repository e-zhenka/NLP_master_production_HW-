# Микросервисы (HW)

Микросервисная архитектура для настройки RabbitMQ в реальных условиях
Этот проект демонстрирует микросервисную архитектуру системы машинного обучения с использованием RabbitMQ для организации очередей сообщений. 

## Архитектура 

Система состоит из четырех основных сервисов:

1. **Сервис признаков** (`features.py`):
Генерирует тестовые признаки и истинные метки.
Отправляет данные в очереди RabbitMQ: features и y_true.
Работает в бесконечном цикле с интервалом в 5 секунд.
Добавляет уникальный идентификатор к каждому сообщению на основе текущей даты в формате timestamp.
Форматирует сообщения как словари для передачи, обеспечивая соответствие ID между признаками и истинными значениями.

2. **Сервис модели** (`model.py`):
Получает данные признаков из очереди features.
Запускает простую тестовую модель, вычисляющую сумму признаков.
Отправляет предсказания в очередь y_pred, сохраняя ID сообщений для отслеживания.

3. **Сервис метрик** (`metrics.py`):
Получает истинные метки и предсказания из двух разных очередей.
Сопоставляет пары по ID сообщений и вычисляет абсолютные ошибки (AE = |Ytrue - Ypred|).
Записывает результаты в CSV файл logs/metric_log.csv, инициализируя таблицу с именами столбцов: id, y_true, y_pred, absolute_error.

4. **Сервис визуализации** (`plot.py`):
Отслеживает файл metric_log.csv.
Создает и обновляет гистограмму распределения абсолютных ошибок.
Сохраняет график в файл logs/error_distribution.png каждые 10 секунд.

## Требования

- Docker
- Docker Compose

## Структура проекта

```
NLP_master_production_HW-
├── Dockerfile
├── docker-compose.yml
├── features.py
├── model.py
├── metrics.py
├── plot.py
├── logs/
│   ├── metric_log.csv
│   └── error_distribution.png
└── README.md
```

## Запуск проекта

1. Клонируйте репозиторий
2. Перейдите в директорию проекта
3. Запустите сервисы с помощью Docker Compose:

```bash
docker-compose up --build
```

Это запустит все сервисы и RabbitMQ. Система автоматически начнет генерировать предсказания и записывать метрики.

## Мониторинг

- Интерфейс управления RabbitMQ: http://localhost:15672 (guest/guest)
- Метрики записываются в: `logs/metric_log.csv`
- График распределения ошибок: `logs/error_distribution.png`

## Детали сервисов

### Поток данных
1. Сервис признаков генерирует тестовые данные и отправляет их в RabbitMQ
2. Сервис модели обрабатывает признаки и делает предсказания
3. Сервис метрик объединяет предсказания с истинными значениями и вычисляет ошибки
4. Сервис визуализации отображает распределение ошибок

### Переменные окружения
- `RABBITMQ_HOST`: Адрес сервера RabbitMQ (по умолчанию: rabbitmq)
- `CSV_FILE`: Путь к файлу логов метрик (по умолчанию: /app/logs/metric_log.csv)
- `IMG_FILE`: Путь к графику распределения ошибок (по умолчанию: /app/logs/error_distribution.png)

## Конфигурация Docker

Проект использует Docker для контейнеризации и включает:
- Базовый образ Python 3.9 slim
- Автоматическое монтирование томов для логов
- Проверки работоспособности для RabbitMQ
- Управление зависимостями сервисов

## Примечания

Это демонстрационный проект с использованием тестовых данных и простой модели.
Система спроектирована для демонстрации принципов микросервисной архитектуры.
Все сервисы контейнеризированы и могут масштабироваться независимо.
Сохранение данных осуществляется через Docker volumes.

## Логирование метрик:

Создание файла metric_log.csv в папке logs/, который будет хранить таблицу с колонками: id, y_true, y_pred, absolute_error.
Каждая итерация сервиса features будет добавлять новую запись в файл, включая уникальный идентификатор, истинные метки, предсказания и абсолютные ошибки.

## Сервис визуализации:

Новый сервис plot.py, который будет бесконечно читать metric_log.csv и строить гистограмму распределения абсолютных ошибок, обновляя график каждые 10 секунд.
```
